{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing Images (color)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the images\n",
    "img = cv2.imread(\"IAM Dataset/forms/a01-000u.png\")\n",
    "\n",
    "# Convert Image to Image HSV\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Defining lower and upper bound HSV values\n",
    "lower = np.array([0, 0, 30])\n",
    "upper = np.array([255, 100, 100])\n",
    "\n",
    "\n",
    "# Defining mask for detecting color\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing Images (lines)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Reading the required image in\n",
    "# which operations are to be done.\n",
    "# Make sure that the image is in the same\n",
    "# directory in which this python program is\n",
    "img = cv2.imread(\"IAM Dataset/forms/a01-000u.png\")\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use canny edge detection\n",
    "edges = cv2.Canny(gray,50,150,apertureSize=3)\n",
    "\n",
    "# Apply HoughLinesP method to\n",
    "# to directly obtain line end points\n",
    "lines_list =[]\n",
    "lines = cv2.HoughLinesP(\n",
    "            edges, # Input edge image\n",
    "            1, # Distance resolution in pixels\n",
    "            np.pi/180, # Angle resolution in radians\n",
    "            threshold=100, # Min number of votes for valid line\n",
    "            minLineLength=5, # Min allowed length of line\n",
    "            maxLineGap=10 # Max allowed gap between line for joining them\n",
    "            )\n",
    "\n",
    "# Iterate over points\n",
    "for points in lines:\n",
    "      # Extracted points nested in the list\n",
    "    x1,y1,x2,y2=points[0]\n",
    "    # Draw the lines joing the points\n",
    "    # On the original image\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    # Maintain a simples lookup list for points\n",
    "    lines_list.append([(x1,y1),(x2,y2)])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"IAM Dataset/forms/a01-000u.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = cv2.bitwise_not(gray)\n",
    "bw = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \\\n",
    "                                cv2.THRESH_BINARY, 15, -2)\n",
    "\n",
    "horizontal=np.copy(bw)\n",
    "\n",
    "horizontalStructure=cv2.getStructuringElement(cv2.MORPH_RECT, (200,1))\n",
    "horizontal = cv2.erode(horizontal, horizontalStructure)\n",
    "horizontal = cv2.dilate(horizontal, horizontalStructure)\n",
    "\n",
    "plt.imshow(horizontal)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Page Segmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def findHorizontalLines(img):\n",
    "    img = cv2.imread(img)\n",
    "\n",
    "    #convert image to greyscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # set threshold to remove background noise\n",
    "    thresh = cv2.threshold(gray,30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "    # define rectangle structure (line) to look for: width 100, hight 1. This is a\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (200,1))\n",
    "\n",
    "    # Find horizontal lines\n",
    "    lineLocations = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, horizontal_kernel, iterations=1)\n",
    "\n",
    "    return lineLocations\n",
    "\n",
    "\n",
    "ll=findHorizontalLines(\"IAM Dataset/forms/a01-000u.png\")\n",
    "plt.imshow(ll)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandasql as ps\n",
    "import pandas as pd\n",
    "def linePosition(lineLoc):\n",
    "    df_lineLocations = pd.DataFrame(lineLoc.sum(axis=1)).reset_index()\n",
    "    df_lineLocations.columns = ['rowLoc', 'LineLength']\n",
    "    df_lineLocations['line'] = 0\n",
    "    df_lineLocations['line'][df_lineLocations['LineLength'] > 100] = 1\n",
    "    df_lineLocations['cumSum'] = df_lineLocations['line'].cumsum()\n",
    "\n",
    "\n",
    "\n",
    "    query = '''\n",
    "    select row_number() over (order by cumSum) as SegmentOrder\n",
    "    , min(rowLoc) as SegmentStart\n",
    "    , max(rowLoc) - min(rowLoc) as Height\n",
    "    from df_lineLocations\n",
    "    where line = 0\n",
    "    --and CumSum !=0\n",
    "    group by cumSum\n",
    "    '''\n",
    "\n",
    "    df_SegmentLocations  = ps.sqldf(query, locals())\n",
    "    return df_SegmentLocations\n",
    "\n",
    "lp=linePosition(ll)\n",
    "lp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Dataset without noise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "def pageSegmentation1(img):\n",
    "    lineLocations = findHorizontalLines(img)\n",
    "    w = lineLocations.shape[1]\n",
    "    df_SegmentLocations = linePosition(lineLocations)\n",
    "    img = cv2.imread(img)\n",
    "    im2 = img.copy()\n",
    "    i = df_SegmentLocations['Height'].idxmax()\n",
    "    y = df_SegmentLocations['SegmentStart'][i]\n",
    "    h = df_SegmentLocations['Height'][i]\n",
    "    cropped = im2[y:y + h, 0:w]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "\n",
    "\n",
    "directory = \"IAM Dataset/forms\"\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        segment = pageSegmentation1(f)\n",
    "        cv2.imwrite(\"IAM Dataset/formsSegment/\"+filename, segment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "l_img = np.zeros((2500,2500,3), np.uint8)\n",
    "l_img.fill(255)\n",
    "plt.show"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Squaring Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def rectangImage(img):\n",
    "    l_img = np.zeros((2500,2500,3), np.uint8)\n",
    "    l_img.fill(255)\n",
    "    s_img = cv2.imread(img)\n",
    "    l_img[0:s_img.shape[0], 0:s_img.shape[1]] = s_img\n",
    "    return l_img\n",
    "im=rectangImage(\"IAM Dataset/formsSegment/a01-000u.png\")\n",
    "plt.imshow(im)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "directory = \"IAM Dataset/formsSegment\"\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        image = rectangImage(f)\n",
    "        cv2.imwrite(\"IAM Dataset/rectFormsSegment/\"+filename, image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading file forms, containing the info of the images in IAM Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('IAM Dataset/forms.txt', sep=\" \", header=None)\n",
    "data.columns = [\"form id\",\"writerId\",\"nSentences\",\"wordSegmentation\",\"nLine\",\"nLineCorrectlySegmented\",\"nWord\",\"nWordCorrectlySegmented\"]\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Drop all unused features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data=data.drop([\"nSentences\",\"wordSegmentation\",\"nLine\",\"nLineCorrectlySegmented\",\"nWord\",\"nWordCorrectlySegmented\"], axis=1)\n",
    "data.nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How many writers we have and how many text wrote each one of them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[\"writerId\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data[\"writerId\"].value_counts().value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#set the number to select only writers with more than X written\n",
    "minimumNumPaperForEachWriter=4\n",
    "is_multi = data[\"writerId\"].value_counts() >= minimumNumPaperForEachWriter\n",
    "filtered = data[data[\"writerId\"].isin(is_multi[is_multi].index)]\n",
    "NWriters=len(filtered[\"writerId\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Create list of writers with less than X papers\n",
    "is_multi = data[\"writerId\"].value_counts() < minimumNumPaperForEachWriter\n",
    "filtered = data[data[\"writerId\"].isin(is_multi[is_multi].index)]\n",
    "lw =filtered[\"writerId\"].tolist()\n",
    "print(len(lw))\n",
    "lw = list(dict.fromkeys(lw))\n",
    "len(lw)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataWriterNotRemoved = pd.DataFrame(data[data[\"writerId\"].isin(lw)==False])\n",
    "dataWriterNotRemoved"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NWriters=len(dataWriterNotRemoved[\"writerId\"].value_counts())\n",
    "NWriters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resizing and Thresholding function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def thresholding(img):\n",
    "    img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret,thresh = cv2.threshold(img_gray,80,255,cv2.THRESH_BINARY_INV)\n",
    "    return thresh"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Img Size than load the data of selected writer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SizeImg=500\n",
    "def loadData():\n",
    "    listWriters = dataWriterNotRemoved[\"writerId\"].tolist()\n",
    "    imgArray = []\n",
    "\n",
    "    for i, row in dataWriterNotRemoved.iterrows():\n",
    "        im=cv2.imread(\"IAM Dataset/rectFormsSegment/\"+row[\"form id\"]+\".png\")\n",
    "        im=image_resize(im,SizeImg)\n",
    "        im=thresholding(im)\n",
    "        imgArray.append(im)\n",
    "    return imgArray, listWriters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X, y = loadData()\n",
    "print(len(X))\n",
    "print(len(y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import PIL.ImageOps\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Sequential, Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Add\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "def halfDeepWriter(input_shape, classes, frac=1):\n",
    "    patch_1 = Input(shape=input_shape)\n",
    "\n",
    "    out1 = Conv2D(int(96*frac), kernel_size=5, strides=2, activation='relu')(patch_1)\n",
    "    out1 = MaxPooling2D(3, strides=2)(out1)\n",
    "\n",
    "    out1 = Conv2D(int(256*frac), kernel_size=3, activation='relu')(out1)\n",
    "    out1 = MaxPooling2D(3, strides=2)(out1)\n",
    "\n",
    "    out1 = Conv2D(int(384*frac), kernel_size=3, activation='relu')(out1)\n",
    "    out1 = Conv2D(int(384*frac), kernel_size=3, activation='relu')(out1)\n",
    "    out1 = Conv2D(int(256*frac), kernel_size=3, activation='relu')(out1)\n",
    "    out1 = MaxPooling2D(3, strides=2)(out1)\n",
    "\n",
    "    out1 = Flatten()(out1)\n",
    "    out1 = Dense(int(1024*frac), activation='relu')(out1)\n",
    "    out1 = Dropout(0.5)(out1)\n",
    "\n",
    "    out1 = Dense(int(1024*frac), activation='relu')(out1)\n",
    "    out1 = Dropout(0.5)(out1)\n",
    "\n",
    "    out1 = Dense(classes, activation='softmax')(out1)\n",
    "\n",
    "    model = Model(inputs=patch_1, outputs=out1)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class dataGeneratorHalfDeepWriter(tensorflow.keras.utils.Sequence):\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True, w=80):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.inputX = X\n",
    "        self.inputY = y\n",
    "        self.w = w\n",
    "        self.h = self.inputX[0].shape[0]\n",
    "        self.total = len(X)\n",
    "        self.indexes = np.arange(self.total)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(self.total / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Generate data\n",
    "        return self.__data_generation(indexes)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batchIndexes):\n",
    "        'Generates data containing batch_size samples' # X : (2, n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.zeros((self.batch_size, self.h, self.w))\n",
    "        y = np.empty((self.batch_size, self.inputY.shape[-1]), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(batchIndexes):\n",
    "            # Black Image\n",
    "            tmpImg = np.zeros((self.h, self.w))\n",
    "\n",
    "            # Starting column position\n",
    "            y_pos1 = int(np.random.randint(low=0,\n",
    "                        high=max(self.inputX[ID].shape[1]-self.w//3, 1),\n",
    "                        size=1))\n",
    "\n",
    "            # Placing Image in black image\n",
    "            tmpImg1 = (self.inputX[ID])[:, y_pos1:y_pos1+self.w]\n",
    "\n",
    "            # Placing Image in output\n",
    "            X[i, 0:tmpImg1.shape[0], 0:tmpImg1.shape[1]] = tmpImg1\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.inputY[ID]\n",
    "\n",
    "        X = X[:, :, :, np.newaxis]\n",
    "        return X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = halfDeepWriter((SizeImg, SizeImg, 1), NWriters)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,\n",
    "                                                    random_state=40)\n",
    "\n",
    "OHE = OneHotEncoder().fit(np.array(y).reshape(-1, 1))\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "y_train_OHE = OHE.fit_transform(y_train).toarray()\n",
    "y_test_OHE = OHE.transform(y_test).toarray()\n",
    "\n",
    "train_gen = dataGeneratorHalfDeepWriter(X_train, y_train_OHE, batch_size=32, w=SizeImg)\n",
    "test_gen = dataGeneratorHalfDeepWriter(X_test, y_test_OHE, batch_size=32, w=SizeImg)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = model.fit(train_gen, validation_data=test_gen, epochs=200, callbacks=[ ModelCheckpoint(filepath='content/best.hdf5',\n",
    "                             save_best_only=True, monitor='acc', mode='max',\n",
    "                            ), ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Resume from checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_weights_path = \"./best.hdf5\"\n",
    "if model_weights_path:\n",
    "    model.load_weights(model_weights_path)\n",
    "    scores = model.evaluate_generator(test_gen, steps=round(len(X_test)/32))\n",
    "    print(\"Accuracy: \", scores[1])\n",
    "else:\n",
    "    print(\"Set model weights file to load in the 'model_weights_path' variable\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}